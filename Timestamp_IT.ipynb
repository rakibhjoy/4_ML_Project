{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RiRMT3v1_oY",
        "outputId": "c1d96bb1-471a-4755-9291-580552f46fec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install -y ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuXmhI9z4MU3",
        "outputId": "821791b1-6090-4830-def5-9d6bc6af1bfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connecting to security.\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [C\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,804 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,078 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,092 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,566 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,262 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,763 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,751 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,917 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,404 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [56.4 kB]\n",
            "Fetched 33.2 MB in 4s (7,765 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFQZjrgl_Tvw",
        "outputId": "170cf823-ad6f-4e4c-b4d2-b3428a07299f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/3.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
        "    \"\"\"\n",
        "    Extract audio from video file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\" Extracting audio from video...\")\n",
        "        video = VideoFileClip(video_path)\n",
        "        video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(\"Error extracting audio:\", e)\n",
        "        return None\n",
        "\n",
        "def transcribe_audio(audio_path, model_name=\"base\"):\n",
        "    \"\"\"\n",
        "    Transcribe audio using Whisper and return transcript segments.\n",
        "    \"\"\"\n",
        "    print(\"Transcribing audio using Whisper...\")\n",
        "    model = whisper.load_model(model_name)\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result['segments']\n",
        "\n",
        "def print_transcript_segments(segments):\n",
        "    \"\"\"\n",
        "    Print transcript segments for inspection.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Transcript Segments ---\")\n",
        "    for segment in segments:\n",
        "        start = segment['start']\n",
        "        end = segment['end']\n",
        "        text = segment['text']\n",
        "        print(f\"[{start:.2f}s - {end:.2f}s]: {text}\")\n",
        "\n",
        "def get_timestamp_for_query(video_path, query, similarity_threshold=70, model_name=\"base\"):\n",
        "    \"\"\"\n",
        "    Extract audio, transcribe, print segments, and search for fuzzy query match.\n",
        "    Returns start time in seconds if found, else None.\n",
        "    \"\"\"\n",
        "    audio_path = extract_audio(video_path)\n",
        "    if audio_path is None:\n",
        "        return None\n",
        "\n",
        "    segments = transcribe_audio(audio_path, model_name=model_name)\n",
        "    print_transcript_segments(segments)\n",
        "\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    for segment in segments:\n",
        "        segment_text = segment['text'].lower()\n",
        "        similarity = fuzz.partial_ratio(query_lower, segment_text)\n",
        "        if similarity >= similarity_threshold:\n",
        "            print(f\"\\nMatch found with similarity {similarity}%:\")\n",
        "            print(f\"Segment text: {segment['text']}\")\n",
        "            return segment['start']\n",
        "\n",
        "    print(\"\\n Query not found in transcript.\")\n",
        "    return None\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"\n",
        "    Convert seconds to hh:mm:ss string.\n",
        "    \"\"\"\n",
        "    if seconds is None:\n",
        "        return \"Not found\"\n",
        "    hrs = int(seconds // 3600)\n",
        "    mins = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f\"{hrs:02d}:{mins:02d}:{secs:02d}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_path = \"/content/talk_video.mp4\"\n",
        "    query = \"You said he wants to erode the very fabric of civilization and Soros hates humanity.\"\n",
        "\n",
        "    timestamp = get_timestamp_for_query(video_path, query, similarity_threshold=60, model_name=\"base\")\n",
        "\n",
        "    print(\"\\n Timestamp (seconds):\", timestamp)\n",
        "    print(\"Timestamp (hh:mm:ss):\", format_timestamp(timestamp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2NkscQi_w8_",
        "outputId": "d216194c-b8db-4f88-8230-1f306a68fe5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Extracting audio from video...\n",
            "Transcribing audio using Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Transcript Segments ---\n",
            "[0.00s - 5.92s]:  We got easy, we got hard, and we've got impossible. Level one easy, hard mode.\n",
            "[11.84s - 12.88s]:  Level impossible.\n",
            "[16.00s - 16.40s]:  Right!\n",
            "[19.92s - 21.60s]:  I think it's time to bring in the big guns.\n",
            "[21.60s - 24.40s]:  Zach, stand! Line change.\n",
            "[24.40s - 26.96s]:  All right, let's go boys. Time for impossible modes.\n",
            "[30.00s - 31.20s]:  Get me going.\n",
            "[31.20s - 32.80s]:  Yes, we're doing it.\n",
            "[32.80s - 34.80s]:  You get me going.\n",
            "[34.80s - 36.80s]:  A superhuman.\n",
            "[36.80s - 40.80s]:  And I want more, more, more of what you're doing.\n",
            "[40.80s - 42.80s]:  You get me going.\n",
            "[42.80s - 44.00s]:  Zach, let's go!\n",
            "\n",
            " Query not found in transcript.\n",
            "\n",
            "⏱ Timestamp (seconds): None\n",
            "⏰ Timestamp (hh:mm:ss): Not found\n"
          ]
        }
      ]
    }
  ]
}